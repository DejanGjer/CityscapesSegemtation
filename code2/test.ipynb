{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dejang/anaconda3/envs/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from labels import labels, Label\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import ColorJitter, ToTensor\n",
    "import numpy as np \n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSemanticSegmentation, AdamW, get_scheduler\n",
    "import wandb\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "from dataset import Dataset\n",
    "from visualization import visualize_samples, visualize_mask\n",
    "\n",
    "def compute_metrics(metric, num_labels):\n",
    "    with torch.no_grad():\n",
    "        metrics = metric.compute(\n",
    "            num_labels=num_labels,\n",
    "            ignore_index=0,\n",
    "            reduce_labels=False\n",
    "        )\n",
    "        for key, value in metrics.items():\n",
    "            if type(value) is np.ndarray:\n",
    "                metrics[key] = value.tolist()\n",
    "        return metrics\n",
    "    \n",
    "def add_batch_to_metrics(metric, logits, labels):\n",
    "    with torch.no_grad():\n",
    "        logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "        pred_labels = logits.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        print(f\"Labels: {labels.shape}, {np.unique(labels)}\")\n",
    "        print(f\"Preds: {pred_labels.shape}, {np.unique(pred_labels)}\")\n",
    "        metric.add_batch(\n",
    "            predictions=pred_labels,\n",
    "            references=labels\n",
    "        )\n",
    "    return pred_labels\n",
    "    \n",
    "def validate(model, metric, eval_ds, id2labels, num_images_to_log, device):\n",
    "    num_labels = len(id2labels)\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    progress_bar = tqdm(range(len(eval_ds)), desc=f\"Evaluating\")\n",
    "    image_log_dict = {}\n",
    "    for i, batch in enumerate(eval_ds):\n",
    "        print(f\"Eval {i}:\")\n",
    "        input_image = batch[\"pixel_values\"].to(device)\n",
    "        gt_labels = batch[\"labels\"].to(device)\n",
    "        for label in gt_labels:\n",
    "            print(f\"Labels: {label.shape}, {np.unique(label)}\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=input_image, labels=gt_labels)\n",
    "            loss = outputs.loss\n",
    "            eval_loss += loss.item()\n",
    "            pred_labels = add_batch_to_metrics(metric, outputs.logits, gt_labels)\n",
    "        # if i == 0:\n",
    "        #     input_image = input_image.cpu().numpy()\n",
    "        #     gt_labels = gt_labels.cpu().numpy()\n",
    "        #     for i in range(min(gt_labels.shape[0], num_images_to_log)):\n",
    "        #         image_log_dict[f\"eval/image_{i}\"] = wandb.Image(np.transpose(input_image[i], (1, 2, 0)), masks={\n",
    "        #             \"predictions\" : {\n",
    "        #                 \"mask_data\" : pred_labels[i],\n",
    "        #                 \"class_labels\" : id2labels\n",
    "        #             },\n",
    "        #             \"ground_truth\" : {\n",
    "        #                 \"mask_data\" : gt_labels[i],\n",
    "        #                 \"class_labels\" : id2labels\n",
    "        #             }\n",
    "        #         })\n",
    "        progress_bar.update(1)\n",
    "    metric_results = compute_metrics(metric, num_labels)\n",
    "    print(metric_results)\n",
    "    result_dict = {\n",
    "        \"eval/loss\": eval_loss / len(eval_ds),\n",
    "        \"eval/mIoU\": metric_results[\"mean_iou\"],\n",
    "        \"eval/mean_acc\": metric_results[\"mean_accuracy\"],\n",
    "        \"eval/overall_acc\": metric_results[\"overall_accuracy\"],\n",
    "    }\n",
    "    result_dict.update(image_log_dict)\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/dejang/.cache/huggingface/datasets/Chris1___parquet/Chris1--cityscapes-2bd50e1e8cc703b7/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 3/3 [00:00<00:00, 630.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'semantic_segmentation'],\n",
      "    num_rows: 2975\n",
      "})\n",
      "Dataset({\n",
      "    features: ['image', 'semantic_segmentation'],\n",
      "    num_rows: 500\n",
      "})\n",
      "Dataset({\n",
      "    features: ['image', 'semantic_segmentation'],\n",
      "    num_rows: 1525\n",
      "})\n",
      "Dataset is sampled\n",
      "Example from dataset class\n",
      "(1024, 2048, 3)\n",
      "(1024, 2048, 3)\n",
      "[0 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/home/dejang/anaconda3/envs/transformers/lib/python3.11/site-packages/transformers/models/segformer/image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation example from dataset class\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 512, 512])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 512, 512])\n",
      "tensor([ 0,  1,  2,  3,  5,  6,  8,  9, 11, 12, 14])\n",
      "CHECK TEST DATASET\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 512, 512])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 512, 512])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval 0:\n",
      "Labels: torch.Size([512, 512]), [0]\n",
      "Labels: torch.Size([512, 512]), [0]\n",
      "Labels: (2, 512, 512), [0]\n",
      "Preds: (2, 512, 512), [ 0  1  2  3  9 11 14]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dejang/Desktop/Machine Learning/Master ML/DL/Cityscapes Semantic Segmentation/code2/test.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m metric \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmean_iou\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m eval_results \u001b[39m=\u001b[39m validate(model, metric, test_ds, dataset\u001b[39m.\u001b[39mid2label, config\u001b[39m.\u001b[39meval_images_to_log, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(eval_results)\n",
      "\u001b[1;32m/home/dejang/Desktop/Machine Learning/Master ML/DL/Cityscapes Semantic Segmentation/code2/test.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     eval_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     pred_labels \u001b[39m=\u001b[39m add_batch_to_metrics(metric, outputs\u001b[39m.\u001b[39mlogits, gt_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# if i == 0:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m#     input_image = input_image.cpu().numpy()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m#     gt_labels = gt_labels.cpu().numpy()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m#             }\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m#         })\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/dejang/Desktop/Machine Learning/Master ML/DL/Cityscapes Semantic Segmentation/code2/test.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLabels: \u001b[39m\u001b[39m{\u001b[39;00mlabels\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(labels)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPreds: \u001b[39m\u001b[39m{\u001b[39;00mpred_labels\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(pred_labels)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     metric\u001b[39m.\u001b[39madd_batch(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         predictions\u001b[39m=\u001b[39mpred_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         references\u001b[39m=\u001b[39mlabels\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dejang/Desktop/Machine%20Learning/Master%20ML/DL/Cityscapes%20Semantic%20Segmentation/code2/test.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pred_labels\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/evaluate/module.py:486\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(column) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enforce_nested_string_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_feature_format[key], column[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 486\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_feature_format\u001b[39m.\u001b[39mencode_batch(batch)\n\u001b[1;32m    487\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter\u001b[39m.\u001b[39mwrite_batch(batch)\n\u001b[1;32m    488\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid, \u001b[39mTypeError\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1885\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[39mfor\u001b[39;00m key, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1884\u001b[0m     column \u001b[39m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1885\u001b[0m     encoded_batch[key] \u001b[39m=\u001b[39m [encode_nested_example(\u001b[39mself\u001b[39m[key], obj) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m column]\n\u001b[1;32m   1886\u001b[0m \u001b[39mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1885\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[39mfor\u001b[39;00m key, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1884\u001b[0m     column \u001b[39m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1885\u001b[0m     encoded_batch[key] \u001b[39m=\u001b[39m [encode_nested_example(\u001b[39mself\u001b[39m[key], obj) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m column]\n\u001b[1;32m   1886\u001b[0m \u001b[39mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1279\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1276\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1277\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1278\u001b[0m             ):\n\u001b[0;32m-> 1279\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39mfeature, o, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1280\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1281\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1279\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1276\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1277\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1278\u001b[0m             ):\n\u001b[0;32m-> 1279\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39mfeature, o, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1280\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1281\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1279\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1276\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1277\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1278\u001b[0m             ):\n\u001b[0;32m-> 1279\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39mfeature, o, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1280\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1281\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1279\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[39m# be careful when comparing tensors here\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m             \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1276\u001b[0m                 \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(first_elmt, \u001b[39mlist\u001b[39m)\n\u001b[1;32m   1277\u001b[0m                 \u001b[39mor\u001b[39;00m encode_nested_example(schema\u001b[39m.\u001b[39mfeature, first_elmt, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m first_elmt\n\u001b[1;32m   1278\u001b[0m             ):\n\u001b[0;32m-> 1279\u001b[0m                 \u001b[39mreturn\u001b[39;00m [encode_nested_example(schema\u001b[39m.\u001b[39mfeature, o, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m   1280\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(obj)\n\u001b[1;32m   1281\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:1284\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (Audio, Image, ClassLabel, TranslationVariableLanguages, Value, _ArrayXD)):\n\u001b[0;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m schema\u001b[39m.\u001b[39mencode_example(obj) \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.11/site-packages/datasets/features/features.py:513\u001b[0m, in \u001b[0;36mValue.encode_example\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(value)\n\u001b[1;32m    512\u001b[0m \u001b[39melif\u001b[39;00m pa\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mis_integer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa_type):\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(value)\n\u001b[1;32m    514\u001b[0m \u001b[39melif\u001b[39;00m pa\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mis_floating(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa_type):\n\u001b[1;32m    515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = Dataset(config.checkpoint, config.image_size, config.batch_size, config.to_sample, config.sample_size)\n",
    "test_ds = dataset.get_test_dataloader()\n",
    "print(\"CHECK TEST DATASET\")\n",
    "example = next(iter(test_ds))\n",
    "ex_image = example[\"pixel_values\"]\n",
    "ex_labels = example[\"labels\"]\n",
    "print(type(ex_image))\n",
    "print(ex_image.shape)\n",
    "print(type(ex_labels))\n",
    "print(ex_labels.shape)\n",
    "print(torch.unique(ex_labels[0]))\n",
    "num_labels = dataset.get_num_labels()\n",
    "\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(\"segformer-b0-cityscapes/nvidia-mit-b0_1\", id2label=dataset.id2label, label2id=dataset.label2id)\n",
    "# prepare training device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "eval_results = validate(model, metric, test_ds, dataset.id2label, config.eval_images_to_log, device)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
